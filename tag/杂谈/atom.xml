<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>http://mingshen.eu.org</id>
    <title>猫猫转圈圈~ • Posts by &#34;杂谈&#34; tag</title>
    <link href="http://mingshen.eu.org" />
    <updated>2023-04-01T08:05:44.000Z</updated>
    <category term="AI" />
    <category term="教程" />
    <category term="Stable Diffusion" />
    <category term="杂谈" />
    <entry>
        <id>http://mingshen.eu.org/2023/04/01/note/ai/sd/%E7%AC%AC%E4%B8%80%E7%AB%A0/</id>
        <title>漫谈Stable Diffusion-第一章</title>
        <link rel="alternate" href="http://mingshen.eu.org/2023/04/01/note/ai/sd/%E7%AC%AC%E4%B8%80%E7%AB%A0/"/>
        <content type="html">&lt;h1 id=&#34;漫谈stable-diffusion-第一章&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#漫谈stable-diffusion-第一章&#34;&gt;#&lt;/a&gt; 漫谈 Stable Diffusion - 第一章&lt;/h1&gt;
&lt;h2 id=&#34;前言&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#前言&#34;&gt;#&lt;/a&gt; 前言&lt;/h2&gt;
&lt;p&gt;这篇文章主要是谈一下目前我对 Stable Diffusion（以下简称 SD）的一些认识和一些简单的 SD 入门知识。&lt;/p&gt;
&lt;h2 id=&#34;了解stable-diffusion&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#了解stable-diffusion&#34;&gt;#&lt;/a&gt; 了解 Stable Diffusion&lt;/h2&gt;
&lt;h3 id=&#34;什么是stable-diffusion&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#什么是stable-diffusion&#34;&gt;#&lt;/a&gt; 什么是 Stable Diffusion&lt;/h3&gt;
&lt;p&gt;Stable Diffusion 是由 Stability AI 开发并开源的 AI 绘画扩散模型，Stability 官方提供收费的线上版本 DreanStudio 和 Reimagine 服务。（简单来说，DreamStudio 相当于用他们的 GPU 算图，Reimagine 相当于加强版的 img2img）&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://s2.loli.net/2023/04/01/MVrvTPyJE5hYKoS.png&#34; alt=&#34;Picsee-20230401174425&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;stable-diffusion-的优势是什么&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#stable-diffusion-的优势是什么&#34;&gt;#&lt;/a&gt; Stable Diffusion 的优势是什么&lt;/h3&gt;
&lt;h4 id=&#34;开源社区的维护&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#开源社区的维护&#34;&gt;#&lt;/a&gt; 开源社区的维护&lt;/h4&gt;
&lt;p&gt;作为开源的扩散模型，Stable Diffusion 有庞大的维护者团体，有时候更新频率甚至以分钟来计数（不像 OpenAI 嘴上说着 Open 却一直想着搞钱）&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（最近 Github 上 SD WebUI 的维护者正在更新 Gradio 库，所以 WebUI 开发版本几乎不能用，可能要等几周后插件和后端适配才行）&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;高度的可拓展性&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#高度的可拓展性&#34;&gt;#&lt;/a&gt; 高度的可拓展性&lt;/h4&gt;
&lt;p&gt;正是由于开源的特性，很多新技术得以在 SD 上实现，比如 LoRA 和 Control Net 都是其他工具不具备的。&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://s2.loli.net/2023/04/01/tLZHowATFRfaOP4.png&#34; alt=&#34;Picsee-20230401175931&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;多平台的兼容性以及较低的性能要求&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#多平台的兼容性以及较低的性能要求&#34;&gt;#&lt;/a&gt; 多平台的兼容性以及较低的性能要求&lt;/h4&gt;
&lt;p&gt;SD 的 Webui 版本支持几乎所有平台，Windows, macOS, GNU/Linux 均有相应的启动脚本。&lt;/p&gt;
&lt;p&gt;我所使用的设备是 Apple m1 MacBook Pro 16g，绕过 CUDA 使用 CPU（其实就是 m1 核显） 计算一张 512*512 的图片仅要四十秒左右。如果显存高并且有 CUDA 的话（以 3090 为例），甚至可以一秒钟出一张。如果不炼模型的话一张性能稍高的游戏显卡可以满足所有需求，炼丹的话 A100 一张完全没问题。商业化成本算是很低。&lt;/p&gt;
&lt;p&gt;* 另：MidJourney 似乎也是用的魔改 SD。&lt;/p&gt;
&lt;h2 id=&#34;简单了解-stable-diffusion-模型&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#简单了解-stable-diffusion-模型&#34;&gt;#&lt;/a&gt; 简单了解 Stable Diffusion 模型&lt;/h2&gt;
&lt;h3 id=&#34;章节前言&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#章节前言&#34;&gt;#&lt;/a&gt; 章节前言&lt;/h3&gt;
&lt;p&gt;由于目前使用 AI 绘画的群体大多数都用其来生成动漫风格的图片，所以本章节演示的图片均为动漫风格图片，实物风同理。&lt;/p&gt;
&lt;h3 id=&#34;模型种类&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#模型种类&#34;&gt;#&lt;/a&gt; 模型种类&lt;/h3&gt;
&lt;h4 id=&#34;checkpoint&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#checkpoint&#34;&gt;#&lt;/a&gt; CheckPoint&lt;/h4&gt;
&lt;p&gt;Checkpoint，通常后缀为 ckpt 或者 safetensors，是 AI 绘画的基础大模型。有 checkpoint 模型就可以直接生成画面，其他种类的模型可以理解为辅助 CheckPoint&lt;/p&gt;
&lt;h4 id=&#34;lora&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#lora&#34;&gt;#&lt;/a&gt; LoRA&lt;/h4&gt;
&lt;p&gt;LoRA（Low-Rank Adaptation of Large Language Models）简单理解就是对大模型的内容进行微调（对于 AI 绘画来说调整很大）&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;比如，GPT-3 有 1750 亿参数，为了让它能干特定领域的活儿，需要做微调，但是如果直接对 GPT-3 做微调，成本太高太麻烦了。&lt;/p&gt;
&lt;p&gt;LoRA 的做法是，冻结预训练好的模型权重参数，然后在每个 Transformer（Transformer 就是 GPT 的那个 T）块里注入可训练的层，由于不需要对模型的权重参数重新计算梯度，所以，大大减少了需要训练的计算量。&lt;/p&gt;
&lt;p&gt;研究发现，LoRA 的微调质量与全模型微调相当，我愿称之为神器。&lt;/p&gt;
&lt;p&gt;要做个比喻的话，就好比是大模型的一个小模型，或者说是一个插件。&lt;/p&gt;
&lt;p&gt;LoRA 本来是给大语言模型准备的，但把它用在 cross-attention layers（交叉关注层）也能影响用文字生成图片的效果。&lt;/p&gt;
&lt;p&gt;── 知乎用户 奉孝翼德 &lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC82MTAwMzE3MTM=&#34;&gt;Stable Diffusion 爱好者常说的 LoRa 是什么？&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;vae&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#vae&#34;&gt;#&lt;/a&gt; Vae&lt;/h4&gt;
&lt;p&gt;Vae 涉及的原理很复杂，在此不赘述。只要不加载 Vae 会使画面发灰就行了&lt;/p&gt;
&lt;h3 id=&#34;针对于模型样例的对比示例为控制变量以下图片-seed采样方式采样步数均相同无后处理&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#针对于模型样例的对比示例为控制变量以下图片-seed采样方式采样步数均相同无后处理&#34;&gt;#&lt;/a&gt; 针对于模型样例的对比示例（为控制变量，以下图片 Seed，采样方式，采样步数均相同，无后处理）&lt;/h3&gt;
&lt;p&gt;Anything V3.0 Checkpoint，不加载 LoRA&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://s2.loli.net/2023/04/01/QNmSEcC4dLuODos.png&#34; alt=&#34;00010-3405425322&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Anything V3.0 Checkpoint，加载 chibi LoRA&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://s2.loli.net/2023/04/01/sxzlkPACHgbcUaQ.png&#34; alt=&#34;00013-3405425322&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Anything V3.0 Checkpoint，加载 Nahida LoRA&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://s2.loli.net/2023/04/01/fuRtNcDlvW8Pkxi.png&#34; alt=&#34;00015-3405425322&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Pastel-Mix Checkpoint，不加载 LoRA&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://s2.loli.net/2023/04/01/UnTbIXHc29hewCS.png&#34; alt=&#34;00011-3405425322&#34; /&gt;&lt;/p&gt;
&lt;p&gt;由此可以看出不同的模型对画面的影响&lt;/p&gt;
&lt;h2 id=&#34;商业化前景&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#商业化前景&#34;&gt;#&lt;/a&gt; 商业化前景&lt;/h2&gt;
&lt;p&gt;现在写实风格的 Checkpoint 最主要的还是 sd 模型，可以到抱脸站（Hugging Face）或者其他模型网站下载。&lt;/p&gt;
&lt;p&gt;AI 绘图通过炼制模型低成本地生成基本图片，经过轻度人工润色，以实现商业化。（亦可作为设计师的灵感来源。）&lt;/p&gt;
&lt;p&gt;目前比较低成本的方式是通过租用云 GPU 服务器（几块钱一小时）训练自己的 LoRA（训练量小，需求的图片训练集小，速度快，配置要求低）。非常不推荐训练 Checkpoint（ckpt 一般通过合并多个模型来实现炼制）。通过自己的 LoRA 结合 sd 模型来达到需求&lt;/p&gt;
&lt;p&gt;已有人成功过，详见&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMVpYNHkxVTdXeS8/c3BtX2lkX2Zyb209MzMzLjMzNy5zZWFyY2gtY2FyZC5hbGwuY2xpY2s=&#34;&gt;AI Lora 技术，跑通炼实物模型 + 写实风格，商业化还差半步～&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMUprNHkxYjdtcy8/c3BtX2lkX2Zyb209MzMzLjc4OC50b3BfcmlnaHRfYmFyX3dpbmRvd19oaXN0b3J5LmNvbnRlbnQuY2xpY2smYW1wO3ZkX3NvdXJjZT01MmI4ZThjZDBlZjA0OGVkMDdmNzU1ZDE3YzY3NzRiNw==&#34;&gt;摩飞（Morphy Richards）生活家电产品风格 lora 训练效果&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&#34;补充说明&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#补充说明&#34;&gt;#&lt;/a&gt; 补充说明&lt;/h2&gt;
&lt;p&gt;本专栏还会有第二期，会讲解 WebUI 各项功能的用法和具体介绍 ControlNet 的用法，敬请期待。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;跑图的话 4g 左右显存 N 卡就够了，训练的话要 8g 显存的 n 卡起步（至少 RTX 3070+）云服务器方式我没试过，但是很多人炼丹会选用&lt;/strong&gt;&lt;/p&gt;
</content>
        <category term="Stable Diffusion" />
        <category term="杂谈" />
        <updated>2023-04-01T08:05:44.000Z</updated>
    </entry>
</feed>
